# LocalAI
OPENAI_API_BASE=http://localhost:8080/v1
OPENAI_API_KEY=localai

# Models
LLM_MODEL=Mistral-7b-search
EMBEDDING_MODEL=All-MiniLM-L6-v2-Embedding-GGUF

# Generation safety
LLM_MAX_TOKENS=800
LLM_TEMPERATURE=0.3
SLEEP_SECONDS = 0.05

# ------------------ Safety parameters ------------------
CHUNK_SIZE = 500
CHUNK_OVERLAP = 100
BATCH_SIZE = 1          # critical for memory safety
SLEEP_SECONDS = 0.05


# ----------------- Quiz Parameters -----------------
WINDOW_SIZE = 5         # BOE chunks per generation
MCQS_PER_WINDOW = 1      # small = safe
SLEEP_SECONDS = 0.2